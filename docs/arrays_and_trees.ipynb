{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `parllel`\n",
    "\n",
    "`parllel` is a modular, flexible framework for developing performant algorithms in Reinforcement Learning.\n",
    "\n",
    "Rather than being a library of algorithm implementations, it instead provides primitive types that are useful for research in RL, then makes it easier to optimize algorithms for speed. `parllel` supports recurrent agents/algorithms, visual RL, multi-agent RL, and RL on graphs/pointclouds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arrays\n",
    "\n",
    "One of the most fundamental types in `parllel` is the `Array`. It's similar to a `numpy` array, but is intended for data storage rather than math operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from parllel import Array\n",
    "\n",
    "array = Array(batch_shape=(5, 4), dtype=np.float32)  # use batch_shape instead of shape\n",
    "array[:] = np.arange(4)\n",
    "print(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do math operations, we can get a view as an ndarray (this operation does not copy the data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndarray = array.to_ndarray()\n",
    "print(ndarray.sum(axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### padding\n",
    "In RL, we often need to save state between batches/iterations. Since this state is often associated with time (e.g. next_observation, previous_action, etc.), a convenient place to store this information is in the array itself. For this, we use the `padding` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = Array(batch_shape=(5, 4), dtype=np.float32, padding=1)\n",
    "array[:] = np.arange(4)\n",
    "array[5] = [4, 5, 6, 7]  # note that this appears to be out of bounds!\n",
    "print(array)\n",
    "print(array[5])\n",
    "print(array[array.last + 1])\n",
    "assert array.last + 1 == 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `array.last + 1` is just syntactic sugar that makes it clear we are writing beyond the end of the array.\n",
    "\n",
    "The values written into the padding are not \"visible\" to normal operations, or when converting to a numpy array. If we want to access them in the next iteration, we can call `rotate()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array[...] = 0\n",
    "array.rotate()\n",
    "print(array[0])  # [4, 5, 6, 7] has been copied to the 0th position in the array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### warning: -1 is not the last element!\n",
    "\n",
    "One important difference between `Array` and `np.ndarray`, is that negative indices are relative to the *beginning* of the array, not the end.\n",
    "\n",
    "This is used to access the last element of the last batch. `array.last` can always be used to access the last element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(array[-1])\n",
    "array[4] = [42, 7, 42, 7]\n",
    "array.rotate()\n",
    "print(array[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### full_size\n",
    "For e.g. replay buffers, we may want to allocate a lot of memory, but only a small window is visible for collecting samples from the environment. This window then slides along the entire replay buffer until its full. We do this using the `full_size` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = Array(batch_shape=(5, 4), dtype=np.float32, full_size=10)  # replaces leading batch dimension, e.g. 5\n",
    "array[...] = 7\n",
    "array.rotate()\n",
    "array[...] = 42\n",
    "array.rotate()\n",
    "print(array)\n",
    "array.rotate()\n",
    "print(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`padding` and `full_size` can be combined arbitrarily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### next & previous\n",
    "RL is often concerned with comparing a value to its past (or future) values. One example is a replay buffer for SAC, where we need both the observation and the next observation to compute the loss for Q-learning. Because Arrays keep track of their indices, we can conveniently access these through the `next` and `previous` attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = Array(batch_shape=(5, 4), dtype=np.float32, padding=1)\n",
    "array[...] = np.arange(np.prod(array.shape)).reshape(array.shape)\n",
    "array[-1] = np.arange(-4, 0)\n",
    "print(array)\n",
    "print(\"previous:\\n\", array.previous)\n",
    "print(\"next:\\n\", array.next)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This also works with slices and elements of the array, not just with the entire array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(array[2])\n",
    "print(\"previous: \", array[2].previous)\n",
    "print(\"next: \", array[2].next)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### storage\n",
    "In RL, we often want to run several environments in parallel for collecting samples faster. In order to avoid copies, we can have these environments write directly to Arrays in shared memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "from operator import setitem\n",
    "\n",
    "array = Array(batch_shape=(5, 4), dtype=np.int32, storage=\"shared\")\n",
    "subarray = array[np.array([1, 3]), np.array([0, 2])]  # unlike for ndarrays, this does not produce a copy\n",
    "\n",
    "p = mp.Process(target=setitem, args=(subarray, ..., 42))  # executes subarray[...] = 42 in another process\n",
    "p.start()\n",
    "p.join()\n",
    "\n",
    "print(array)\n",
    "\n",
    "# array.close()  # always close arrays allocated in shared memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ArrayDict\n",
    "\n",
    "Often in RL, it is useful to store data in a tree structure. This allows for uniform handling of data in many cases, even when the underlying structure is different. The ArrayDict is a simple, lightweight data structure that stores any array-like objects and simplifies handling them.\n",
    "\n",
    "ArrayDict is inspired by TensorDict (and also by JAX trees), but is a lot more flexible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parllel import ArrayDict\n",
    "\n",
    "tree = ArrayDict({\n",
    "    \"observation\": Array(batch_shape=(10, 5, 4), dtype=np.float32),\n",
    "    \"action\": {  # in a multi-agent problem, action might be a dictionary of actions\n",
    "        \"pinky\": Array(batch_shape=(10, 5), dtype=np.int64),\n",
    "        \"the_brain\": Array(batch_shape=(10, 5, 2), dtype=np.float32),\n",
    "    },\n",
    "    \"done\": Array(batch_shape=(10, 5), dtype=bool),\n",
    "})\n",
    "\n",
    "tree[0, 1] = 42 * 10 * 5  # you can write \n",
    "print(tree[0, 1])  # you can index the tree\n",
    "print()\n",
    "print(tree.dtype)  # you can get attributes\n",
    "print()\n",
    "print(tree.to_ndarray().mean(axis=(0, 1)))  # convert to nd.array and calculate the mean across batch dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The leaf nodes can be `Array`, `np.ndarray`, `torch.Tensor`, `jax.numpy.array`, etc.\n",
    "\n",
    "ArrayDict has two methods that are not present in normal python dictionaries: `to_ndarray` and `apply`.\n",
    "\n",
    "`to_ndarray` converts all leaf nodes to `np.ndarray`. `apply` calls a function with each leaf node as an argument (as well as any other args and kwargs), and returns a new `ArrayDict` with the result. `map` is an alias for `apply`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "tensor_tree = tree[0].to_ndarray().apply(torch.from_numpy)\n",
    "print(tensor_tree)\n",
    "print()\n",
    "tensor_tree[1] = 0\n",
    "tensor_tree[2] = 42 * 10 * 5\n",
    "print(tree[0, 2])  # Arrays/ndarrays/tensors all share the same storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the biggest advantages of `ArrayDict` is the ability to treat arrays and array trees identically. In the following code, we don't care if action is a single array or an array tree (as in multi-agent reinforcement learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = tree.to_ndarray()[\"action\"]\n",
    "\n",
    "print(action.mean(), action.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together: Sampling\n",
    "\n",
    "Primitives like Array and ArrayDict allow us to write very powerful and expressive code. For example, sampling (collecting rollouts from the policy) can be implemented as simply as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parllel import dict_map\n",
    "from parllel.cages import SerialCage, TrajInfo\n",
    "from parllel.torch.agents.categorical import CategoricalPgAgent, ModelOutputs, DistParams\n",
    "from parllel.torch.distributions.categorical import Categorical\n",
    "\n",
    "from torch.nn import Linear\n",
    "from gymnasium.envs.classic_control.cartpole import CartPoleEnv\n",
    "\n",
    "batch_T, batch_B = 10, 5\n",
    "\n",
    "# create environments\n",
    "envs = [SerialCage(CartPoleEnv, {}, TrajInfo) for _ in range(batch_B)]\n",
    "\n",
    "# get example action and observation from environment step\n",
    "envs[0].random_step_async()\n",
    "action, observation, _, _, _, _ = envs[0].await_step()\n",
    "\n",
    "# allocate Arrays to store samples based on examples\n",
    "action = dict_map(Array.from_numpy, action, batch_shape=(batch_T, batch_B))\n",
    "observation = dict_map(Array.from_numpy, observation, batch_shape=(batch_T, batch_B), padding=1)\n",
    "reward = Array(batch_shape=(batch_T, batch_B), dtype=np.float32)\n",
    "terminated = Array(batch_shape=(batch_T, batch_B), dtype=bool)\n",
    "truncated = Array(batch_shape=(batch_T, batch_B), dtype=bool)\n",
    "env_info = ArrayDict()\n",
    "\n",
    "# define a model with the correct output for a Categorical distribution\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.pi = Linear(4, 2)\n",
    "        self.value = Linear(4, 1)\n",
    "\n",
    "    def forward(self, observation):\n",
    "        probs = self.pi(observation).softmax(dim=-1)\n",
    "        value = self.value(observation).squeeze(-1)\n",
    "        return ModelOutputs(dist_params=DistParams(probs=probs), value=value)\n",
    "\n",
    "# instantiate an agent, which requires a model and a distribution\n",
    "agent = CategoricalPgAgent(\n",
    "    model=Model(),\n",
    "    distribution=Categorical(dim=2),\n",
    "    example_obs=observation[0],\n",
    ")\n",
    "\n",
    "# reset all environments and write reset observation to 0th position\n",
    "for b, env in enumerate(envs):\n",
    "    env.reset_async(\n",
    "        out_obs=observation[0, b],\n",
    "        out_info=env_info[0, b],\n",
    "    )\n",
    "\n",
    "for t in range(batch_T):\n",
    "\n",
    "    # get new actions from agent\n",
    "    action[t], _ = agent.step(observation[t])\n",
    "\n",
    "    # rollout actions and get new observations, etc.\n",
    "    for b, env in enumerate(envs):\n",
    "        env.step_async(\n",
    "            action[t, b],\n",
    "            out_obs=observation[t + 1, b],\n",
    "            out_reward=reward[t, b],\n",
    "            out_terminated=terminated[t, b],\n",
    "            out_truncated=truncated[t, b],\n",
    "            out_info=env_info[t, b],\n",
    "        )\n",
    "\n",
    "        for b, env in enumerate(envs):\n",
    "            env.await_step()\n",
    "\n",
    "# print results\n",
    "print(ArrayDict({\n",
    "    \"action\": action,\n",
    "    \"observation\": observation,\n",
    "    \"reward\": reward,\n",
    "    \"terminated\": terminated,\n",
    "    \"truncated\": truncated,\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "In many cases, these common operations are already available as pre-built classes (for the above example, `BasicSampler` and `RecurrentSampler`). parllel is designed such that these components are as general and interchangeable as possible, allowing you to simply pick out the desired objects and combine them in the desired way. But each class is also written to be understandable, such that researchers can subclass, override, and customize at whim.\n",
    "\n",
    "This is only a small sample of what is possible with parllel. To get a better idea, please take a look at the `examples` folder."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "parllel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
