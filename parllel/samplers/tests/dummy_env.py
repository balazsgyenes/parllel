import copy
import traceback

import gymnasium as gym
import numpy as np
from gymnasium import spaces
from nptyping import NDArray

from parllel.arrays import Array, buffer_from_dict_example
from parllel.buffers import (Buffer, EnvSamples, NamedTuple, buffer_asarray,
                             buffer_method)
from parllel.types import BatchSpec


class DummyEnv(gym.Env):
    def __init__(
        self,
        action_space: gym.Space,
        observation_space: gym.Space,
        episode_length: int,
        batch_spec: BatchSpec,
        n_batches: int,
        multireward: bool = False,
        reset_automatically: bool = True,
    ) -> None:
        self.observation_space = observation_space
        self.action_space = action_space
        if multireward:
            self.reward_space = spaces.Dict(
                {
                    "alice": spaces.Box(-10, 10, shape=()),
                    "bob": spaces.Box(-10, 10, shape=()),
                }
            )
        else:
            self.reward_space = spaces.Box(-10, 10, shape=())

        self.episode_length = episode_length
        self.batch_spec = batch_spec
        self.reset_automatically = reset_automatically

        # allocate buffers to store data generated by this env
        self._step_ctr = 0
        batch_observation = buffer_from_dict_example(
            self.observation_space.sample(),
            batch_shape=(n_batches * batch_spec.T,),
            name="obs",
            padding=1,
        )
        batch_reward = buffer_from_dict_example(
            self.reward_space.sample(),
            batch_shape=(n_batches * batch_spec.T,),
            name="reward",
            feature_shape=(),
            dtype=np.float32,
        )
        batch_done = Array(
            feature_shape=(),
            batch_shape=(n_batches * batch_spec.T,),
            dtype=bool,
        )
        batch_terminated = Array(
            feature_shape=(),
            batch_shape=(n_batches * batch_spec.T,),
            dtype=bool,
        )
        batch_truncated = Array(
            feature_shape=(),
            batch_shape=(n_batches * batch_spec.T,),
            dtype=bool,
        )
        batch_info = buffer_from_dict_example(
            {"action": self.action_space.sample()},
            batch_shape=(n_batches * batch_spec.T,),
            name="envinfo",
        )
        self._samples = EnvSamples(
            batch_observation,
            batch_reward,
            batch_done,
            batch_terminated,
            batch_truncated,
            batch_info,
        )
        self._batch_resets = Array(
            feature_shape=(),
            batch_shape=(n_batches * batch_spec.T,),
            dtype=bool,
            padding=1,
        )

    def step(self, action: NDArray) -> tuple[Buffer, np.ndarray, bool, bool, NamedTuple]:
        obs = self.observation_space.sample()
        reward = self.reward_space.sample()
        terminated = self._traj_counter >= self.episode_length
        truncated = False
        done = terminated or truncated
        env_info = {"action": copy.deepcopy(action)}

        # check the call stack to determine if this is a "real sample" or not
        # if just getting example or decorrelating, keep overwriting "reset"
        # observation
        names = [frame.name for frame in traceback.extract_stack()]
        if "random_step_async" in names:
            self._samples.observation[0] = obs
        else:
            self._samples.observation[self._step_ctr + 1] = obs
            self._samples.reward[self._step_ctr] = reward
            self._samples.terminated[self._step_ctr] = terminated
            self._samples.truncated[self._step_ctr] = truncated
            self._samples.done[self._step_ctr] = done
            self._samples.env_info[self._step_ctr] = env_info
            self._step_ctr += 1

        self._traj_counter += 1
        return (obs, reward, terminated, truncated, env_info)

    def reset(self, seed=None, options={}) -> tuple[np.ndarray, dict]:
        self._traj_counter = 1
        self._batch_resets[self._step_ctr - 1] = True
        if not self.reset_automatically:
            # sampling batch may have stopped early
            batch_ctr = (self._step_ctr - 1) // self.batch_spec.T + 1
            # advance counter to the next batch
            self._step_ctr = batch_ctr * self.batch_spec.T
        obs = self.observation_space.sample()
        self._samples.observation[self._step_ctr] = obs
        action = (
            self._samples.env_info.action[self._step_ctr - 1]
            if self._step_ctr > 0
            else None
        )
        action = buffer_asarray(action)
        action = buffer_method(action, "copy")
        return obs, {"action": action}

    @property
    def samples(self):
        return self._samples

    @property
    def resets(self):
        return self._batch_resets
